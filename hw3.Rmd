---
title: "hw3"
author: "Wanjia Guo"
date: "12/8/2021"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(315)
```


# Part 1: Predicting a Categorical Outcome using tree models


```{r}
# Load the following packages needed for modeling in this assignment
  
  require(caret)
  require(recipes)
  require(ranger)
  require(cutpointr)

# Import the tweet dataset with embeddings

tweet <- read.csv('https://raw.githubusercontent.com/uo-datasci-specialization/c4-ml-fall-2021/main/content/post/hw2/data/hw1_tweet_final.csv',header=TRUE)

# Recipe for the tweet dataset

blueprint_tweet <- recipe(x  = tweet,
                          vars  = colnames(tweet),
                          roles = c('outcome',rep('predictor',772))) %>%
  step_dummy('month',one_hot=TRUE) %>% 
  step_harmonic('day',frequency=1,cycle_size=7, role='predictor') %>%
  step_harmonic('date',frequency=1,cycle_size=31,role='predictor') %>%
  step_harmonic('hour',frequency=1,cycle_size=24,role='predictor') %>%
  step_normalize(paste0('Dim',1:768)) %>%
  step_normalize(c('day_sin_1','day_cos_1',
                   'date_sin_1','date_cos_1',
                   'hour_sin_1','hour_cos_1')) %>%
  step_rm(c('day','date','hour')) %>%
  step_num2factor(sentiment,
                  transform = function(x) x + 1,
                  levels=c('Negative','Positive'))
```


### Task 1.1. Split the original data into two subsets: training and test. Let the training data have the 80% of cases and the test data have the 20% of the cases.


```{r}

loc      <- sample(1:nrow(tweet), round(nrow(tweet) * 0.8))
df_tr  <- tweet[loc, ]
df_te  <- tweet[-loc, ]

```

### Task 1.2. Use the caret::train() function and ranger engine to train a model with 10-fold cross-validation for predicting the probability of sentiment being positive using a Bagged Trees model with 500 trees.

```{r}

# Randomly shuffle the data

df_tr = df_tr[sample(nrow(df_tr)),]

# Create 10 folds with equal size

folds = cut(seq(1,nrow(df_tr)),breaks=10,labels=FALSE)

# Create the list for each fold 

my.indices <- vector('list',10)
for(i in 1:10){
  my.indices[[i]] <- which(folds!=i)
}

cv <- trainControl(method = "cv",
             index  = my.indices,
             classProbs = TRUE,
             summaryFunction = mnLogLoss)

# Grid settings

grid <- expand.grid(mtry = ncol(df_tr)-1,
                    splitrule='gini',
                    min.node.size=2)


bags <- caret::train(blueprint_tweet,
                     data = df_tr,
                     method = 'ranger',
                     trControl = cv,
                     tuneGrid = grid,
                     metric = 'logLoss',
                     num.trees = 500,
                     max.depth = 60)
```

### Task 1.3. Use the caret::train() function and ranger engine to train a model with 10-fold cross-validation for predicting the probability of sentiment being positive using a Random Forest model with 500 trees. Set the number of predictors to consider to 250 for each tree while growing a random forest.

```{r}
# Grid settings

random_grid <- expand.grid(mtry = 250,
                    splitrule='gini',
                    min.node.size=2)
random_grid

# The only difference for random forests is that I set mtry = 80

# Run the bagged trees by iterating over num.trees values from 1 to 200
  
random <- caret::train(blueprint_tweet,
                       data      = df_tr,
                       method    = 'ranger',
                       trControl = cv,
                       tuneGrid  = random_grid,
                       metric    = 'logLoss',
                       num.trees = 500,
                       max.depth = 60)
```

### Task 1.4 Evaluate the performance of the Bagged Tree models (1.2) and Random Forest Model (1.3) on the test dataset. Calculate and report logLoss (LL), area under the reciever operating characteristic curver (AUC), overall accuracy (ACC), true positive rate (TPR), true negative rate (TNR), and precision (PRE) for three models. When calculating ACC, TPR, TNR, and PRE, assume that we use a cut-off value of 0.5 for the predicted probabilities. Summarize these numbers in a table like the following. Decide and comment on which model you would use to predict sentiment of a tweet moving forward.

Bagged trees: 

```{r}
predicted_bagged <- predict(bags, df_te, type='prob')

head(predicted_bagged)

cut.obj <- cutpointr(x     = predicted_bagged$Positive,
                     class = df_te$sentiment)

bags_auc = auc(cut.obj)

bagged_class <- ifelse(predicted_bagged$Positive>.5,1,0)

bags_confusion <- table(df_te$sentiment,bagged_class)

bags_confusion

bags_ACC = (bags_confusion[2,2]+bags_confusion[1,1])/sum(bags_confusion)

bags_ACC

bags_TPR = bags_confusion[2,2]/(bags_confusion[2,1]+bags_confusion[2,2])

bags_TPR

bags_TNR = bags_confusion[1,1]/(bags_confusion[1,1]+bags_confusion[1,2])

bags_TNR

bags_PRE = bags_confusion[2,2]/(bags_confusion[1,2]+bags_confusion[2,2])

bags_PRE
```

Random forest:

```{r}

predicted_random <- predict(random, df_te, type='prob')

head(predicted_random)

cut.obj <- cutpointr(x     = predicted_random$Positive,
                     class = df_te$sentiment)

random_auc = auc(cut.obj)

random_class <- ifelse(predicted_random$Positive>.5,1,0)

random_confusion <- table(df_te$sentiment,random_class)

random_confusion

random_ACC = (random_confusion[2,2]+random_confusion[1,1])/sum(random_confusion)

random_ACC

random_TPR = random_confusion[2,2]/(random_confusion[2,1]+random_confusion[2,2])

random_TPR

random_TNR = random_confusion[1,1]/(random_confusion[1,1]+random_confusion[1,2])

random_TNR

random_PRE = random_confusion[2,2]/(random_confusion[1,2]+random_confusion[2,2])

random_PRE
```

Performance comparisons:

```{r}
name <- c('Bagged trees', 'Random forest')

LL <- c(bags$results$logLoss,
        random$results$logLoss)
AUC <- c(bags_auc, random_auc)
ACC <- c(bags_ACC, random_ACC)
TPR <- c(bags_TPR, random_TPR)
TNR <- c(bags_TNR, random_TNR)
PRE <- c(bags_PRE, random_PRE)

summary_df <- data.frame(name, LL, AUC, ACC, TPR, TNR, PRE)

summary_df
```

### Task 1.5 Compare the performance of the Bagged Trees Model and Random Forest Model in this assignment to the performance of logistic regression models from the previous assignment. Comment on what you observe. Did Bagged Trees or Random Forest Models perform better than Logistic Regression Models?

Random forest has higher logLoss than Bagged trees, but the AUC for random forest is also higher. I also found the confusion matrix for random forest is worse than the bagged trees models. In particular, bagged trees has higher performance in accuracy, true positive rate, true negative rate, and precision. Comparing to logistic regression, the performance of bagged tree is better, but not always for the random forest. 

(See: https://wanjiag.github.io/EDLD654_ML/hw2.html#task-1.5-evaluate-the-performance-of-the-models-in-1.2-1.3-and-1.4-on-the-test-dataset.-calculate-and-report-logloss-ll-area-under-the-reciever-operating-characteristic-curver-auc-overall-accuracy-acc-true-positive-rate-tpr-true-negative-rate-tnr-and-precision-pre-for-three-models.-when-calculating-acc-tpr-tnr-and-pre-assume-that-we-use-a-cut-off-value-of-0.5-for-the-predicted-probabilities.-summarize-these-numbers-in-a-table-like-the-following.-decide-and-comment-on-which-model-you-would-use-to-predict-sentiment-of-a-tweet-moving-forward.)

# Part 2: Predicting a Continous Outcome using tree models

```{r}
# Import the oregon dataset

oregon <- read.csv('https://raw.githubusercontent.com/uo-datasci-specialization/c4-ml-fall-2021/main/content/post/hw2/data/hw1_oregon_final.csv',header=TRUE)

# Recipe for the oregon dataset

  outcome <- 'score'
  
  id      <- 'id'

  categorical <- c('sex','ethnic_cd','tst_bnch','migrant_ed_fg','ind_ed_fg',
                   'sp_ed_fg','tag_ed_fg','econ_dsvntg','stay_in_dist',
                   'stay_in_schl','dist_sped','trgt_assist_fg',
                   'ayp_dist_partic','ayp_schl_partic','ayp_dist_prfrm',
                   'ayp_schl_prfrm','rc_dist_partic','rc_schl_partic',
                   'rc_dist_prfrm','rc_schl_prfrm','grp_rpt_dist_partic',
                   'grp_rpt_schl_partic','grp_rpt_dist_prfrm',
                   'grp_rpt_schl_prfrm')

  numeric <- c('enrl_grd')

  cyclic <- c('date','month')


blueprint_oregon <- recipe(x     = oregon,
                    vars  = c(outcome,categorical,numeric,cyclic),
                    roles = c('outcome',rep('predictor',27))) %>%
  step_indicate_na(all_of(categorical),all_of(numeric)) %>%
  step_zv(all_numeric()) %>%
  step_impute_mean(all_of(numeric)) %>%
  step_impute_mode(all_of(categorical)) %>%
  step_harmonic('date',frequency=1,cycle_size=31,role='predictor') %>%
  step_harmonic('month',frequency=1,cycle_size=12,role='predictor') %>%
  step_ns('enrl_grd',deg_free=3) %>%
  step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
  step_normalize(c("date_sin_1","date_cos_1","month_sin_1","month_cos_1")) %>%
  step_dummy(all_of(categorical),one_hot=TRUE) %>%
  step_rm(c('date','month'))
```


### Task 2.1. Split the original data into two subsets: training and test. Let the training data have the 80% of cases and the test data have the 20% of the cases.

```{r}
loc      <- sample(1:nrow(oregon), round(nrow(oregon) * 0.8))
df2_tr  <- oregon[loc, ]
df2_te  <- oregon[-loc, ]
```

### Task 2.2. Use the caret::train() function and ranger engine to train a model with 10-fold cross-validation for predicting the scores using a Bagged Trees model with 500 trees.

```{r}

# Randomly shuffle the data

df2_tr = df2_tr[sample(nrow(df2_tr)),]

# Create 10 folds with equal size

folds = cut(seq(1,nrow(df2_tr)),breaks=10,labels=FALSE)

# Create the list for each fold 

my.indices <- vector('list',10)
for(i in 1:10){
  my.indices[[i]] <- which(folds!=i)
}

cv <- trainControl(method = "cv",
                   index  = my.indices)

# Grid settings

grid <- expand.grid(mtry = ncol(df2_tr)-1,
                    splitrule='variance',
                    min.node.size=2)


bags <- caret::train(blueprint_oregon,
                     data = df2_tr,
                     method = 'ranger',
                     trControl = cv,
                     tuneGrid = grid,
                     num.trees = 500,
                     max.depth = 60)
```

### Task 2.3. Use the caret::train() function and ranger engine to train a model with 10-fold cross-validation for predicting the scores using a Random Forest model with 500 trees. Set the number of predictors to consider to 25 for each tree while growing a random forest.

```{r}

grid <- expand.grid(mtry = 25,
                    splitrule='variance',
                    min.node.size=2)


random <- caret::train(blueprint_oregon,
                     data = df2_tr,
                     method = 'ranger',
                     trControl = cv,
                     tuneGrid = grid,
                     num.trees = 500,
                     max.depth = 60)
```

### Task 2.4 Evaluate the performance of the Bagged Tree models (2.2) and Random Forest Model (2.3) on the test dataset. Calculate and report the root mean squared error (RMSE), mean absolute error (MAE), and R-square. Summarize these numbers in a table like the following.

Bagged trees:

```{r}

predicted_bags <- predict(bags, df2_te)

bagged_rmse = sqrt(mean((df2_te$score - predicted_bags)^2))
  
bagged_mae = mean(abs(df2_te$score - predicted_bags))

bagged_rsq = cor(df2_te$score,predicted_bags)^2

```

Predicted trees:

```{r}
predicted_random <- predict(random, df2_te)

random_rmse = sqrt(mean((df2_te$score - predicted_random)^2))
  
random_mae = mean(abs(df2_te$score - predicted_random))

random_rsq = cor(df2_te$score,predicted_random)^2
```


```{r}
name <- c('Bagged trees', 'Random forest')
RMSE <- c(bagged_rmse, random_rmse)
MAE <- c(bagged_mae, random_mae)
R_sq <- c(bagged_rsq, random_rsq)

summary_df <- data.frame(name, RMSE, MAE, R_sq)

summary_df
```

### Task 1.5 Compare the performance of the Bagged Trees Model and Random Forest Model in this assignment to the performance of linear regression models from the previous assignment. Comment on what you observe. Did Bagged Trees or Random Forest Models perform better than Linear Regression Models in predicting the test scores?

Overall, random forest performs better than bagged tree model. Both Random forest and bagged tree models also perform better than the previous Linear Regression Model.
